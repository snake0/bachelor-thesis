%# -*- coding: utf-8-unix -*-
%%==================================================
%% chapter05.tex for SJTU Bachelor Thesis
%%==================================================

%\bibliographystyle{sjtu2}%[此处用于每章都生产参考文献]
\chapter{结论}
本文通过总结三个领域的最新进展：深度增强学习算法、数据中心网络中的数据流负载均衡算法和交换机处的缓冲区流量调度算法，针对5G Cloud RAN场景下的负载均衡问题提出了一个新的解决方案，此处的负载均衡是指广义的负载均衡，即包含了从端系统到交换机到端系统整体路径上的负载均衡，涵盖数据流的优先级标记、交换机缓存处的入队、出队操作及选路、拥塞信息采集等一系列过程。该解决方案是一个混合型的结构，对于短数据流采用性能极佳的DRILL分布式负载均衡算法，基于本地信息给出快速的均衡决策；利用离散形式的策略梯度算法和决定性（连续空间下）的actor-critic算法集中式地解决了长数据流的选路、流速率、优先级和对于网络架构中交换机处采用的MLFQ的队列阈值的实时部署，根据动态的网络流量情况，以及以往数据得到的经验，给出一种接近最优的流量优化方法。

由于实验条件的限制，本文没有在实际场景下做相关实验，只是在ns-3仿真软件中做了性能分析。我们知道，数据中心网络中数据流量变化迅速，应用种类繁多，采用的网络拓扑结构各不相同（层状、网状或混合型结构、对称或非对称网络、不同类型的商品交换机和端系统等），这些都是对流量的负载均衡算法有着根本影响的因素。本文提出的系统比较适用于Clos架构的数据中心网络，如果网络是3层的，那么在实际部署过程中就需要对分布式负载均衡算法进行改动。另外，我们还需要考虑到深度增强学习模型的启动问题，即当中心组件发生宕机或其他故障时，此时其网络参数需要提前在硬盘中保存，因为系统重启后，重新训练深度模型所花费的延迟是不可接受的，且在重启后如何利用之前保存的网络参数以迅速恢复对于MLFQ队列阈值和长数据流的实时决策亦是我们需要进一步讨论的问题。

另外，在深度增强学习模型的训练过程中，可以发现其预训练所需的时间很长，因此进一步的研究方向可以对算法的效率进行提升。当然，鉴于人工智能算法的复杂性，目前实际应用中效果较好的模型，如计算机视觉领域的Mask-RCNN，自然语言处理领域的ELMo、BERT，知识图谱领域的KBGAN等算法都需要长时间的预训练，对于深度学习算法的改进是推动整个人工智能时代的动力。我们不能忘记传统算法的优美，亦要利用最前沿模型的强大功能，将二者融合起来才会使问题得到最终解决。
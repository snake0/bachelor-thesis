%# -*- coding: utf-8-unix -*-
\begin{bigabstract}
%\chapter{A Study on Load Balancing Algorithm with Lightweight AI}
This thesis deals with the general load balancing problem in data center networks. Under the scenario of the Cloud Radio Access Network of the fifth generation of wireless communication system, we propose a new paradigm for a combination of load balancing algorithm and flow scheduling algorithm. The system is a mixed model with several hierarchies, namely centralized flow scheduling component and distributed load balancing component. The centralized flow scheduling scheme employs the state-of-the-art deep learning algorithm, Deep Deterministic Policy Gradient and Stochastic Policy Gradient algorithm, to solve the problem of assignment of rate limit, queue priorities and path selection for the long flows in the datacenter network and the thresholds of the Multi Level Feedback Queue commonly used in modern commodity switches. The distributed load balancing algorithm, which addresses the narrowly-sensed load balancing problem, utilizes the recent model DRILL proposed by Soudeh Ghorbani et al., aiming at achieving lower flow complete time and lower total transmission time, not to mention raising the rate of link utilization.

In the first and second generation of wireless communication systems, cellulars or radio access networks (usually shortened as RAN), were separate base stations, each equipped with power, air-conditioning systems, environment monitoring systems, backhaul and other essential components. Each base station has its own radio frequency emission devices, and the radio frequency signals were transferred from the base station on the ground to the antennas, which always resulted in a high loss on the cables. In the third generation of communication systems, however, people employed distributed base station systems, separating remote radio head and baseband unit from each other to the remote radio head to be assigned to the place close to the antennas, given that the optic fibers could extremely reduce the loss of long distance signal transmission. Based on the architecture of distributed systems, Cloud Radio Access Network utilizes the recent large-scale data center network technology to establish the stable, energy-efficient, low-latency, and high-bandwidth connections between baseband units. Besides, the usage of an open platform and real-time virtualization technique enables the dynamic resource allocation between different scenes and in different electronic devices. In such architecture, since the area coverage is much bigger than previous single, separate base stations (when one user switches from one baseband unit to another, it is highly possible that the user is still in the same pool of BBUs), the data flow in the cellular networks can be solved using dynamic and real-time load balancing algorithm in the baseband unit pool.

The traditional problem of load balancing has been widely studied by researchers. Examples like cell zooming has been applied to the second and third generation of wireless communication systems. The highly efficient switching scheme in Cloud Radio Access Network proposed by C. Ran and S. Wang et al. considers the energy condition to achieve the optimal load balancing. They periodically measure the index for balance. When the index is lower than a certain threshold, they re-design the area covered by the base stations to achieve a new status of balance. C. Tsai and M.Moh compared eight methods of load balancing that mainly aim at reducing the communication latency in the scene of Internet of Things. These algorithms either use pre-defined thresholds or metrics to monitor the load or ports of the network switches, or carry out fixed or non real-time strategies. On the contrary, B. Shahriari and M. Moh proposed generic online learning structure using the method of deep reinforcement learning in an partially visible environment, which can be adapted to solve the load balancing problem in the scenario of 5G Cloud Radio Access Network.

Inspired by the work of B. Shahriari and M. Moh, we would like to utilize the great capability of fitting any complex functions of the deep neural networks. Since the aims of load balancing (in a narrow sense) and flow scheduling are the same: reducing the flow completion time, we would like to combine this two scheme into one system, and apply deep reinforcement learning to face with the data center network whose flow features are extremely dynamic since the agent in a reinforcement learning model can handle such problems and make kind of real-time decisions towards the changes.

Hence in this thesis, we first study the deep reinforcement learning algorithms. The very first reinforcement learning algorithms are value based: they use the tables to learn the agentâ€™s proper actions towards different states and rewards given by the environment. By utilizing the great capability of fitting complex functions of the deep neural networks, we can develop deep Q-networks which is of great performance. By introducing experience replay, we can solve the problem discovered by Volodymyr Mnih et al. that the expression for Q values using neural networks is unstable. Besides, Hado van Hasselt introduced Double Deep Q-Networks employing double Q-learning scheme in 2016 to solve the problem of overestimation for the parameters. Different from value-based methods, there are another group of reinforcement learning algorithms that directly determine the policy, namely a sequence of actions taken by the agent. When the action space is discrete, the method is called stochastic policy gradient since the model outputs the distribution of actions, but not a single action. The REINFORCE algorithm proposed by Richard S. Sutton, is a typical stochastic one. By using gradient descent, the algorithm consistently updates its parameters towards the tuples the agent got from multiple attempts in the environment, until the parameters come to convergence. In 2016, David Silver et al. proposed a series of algorithms which belong to deterministic policy gradient. They consider a deterministic policy, in which the neural network outputs the action itself directly. The proposal itself becomes a surprise to most of the researchers since it was previously believed that deterministic policy gradient did not exist or could only be obtained when using a specific model. Deep Deterministic Policy Gradient is a typical algorithm of this type. By using the core idea of actor-critic, there are four neural networks in the model, two of them are actors, the other ones serve as critics. And both actor and critic employ the scheme of replay buffers.

In the third chapter of the thesis, we discuss load balancing in 5G Cloud Radio Access Network. We first consider the architecture and traffic features in data center network in the era of 5G. Multiple architectures have been introduced during these years, among which Fat-tree, Camcube and BCube are three typical structures which aim at different scenarios or applications. Fat-tree is a multi-layer structure whose center is switches, while CamCube is net structure whose center is hosts. BCube is a mixed structure which uses hosts and switches to transfer data at the same time. After the discussion of datacenter network architecture, the definition, targets, and main steps of load balancing in data center networks are introduced. The main steps are the collection of congestion information and path selection for the flows. We then compare the load balancing in data center networks and wide area network to find out what is the main concern in the algorithm design. We finally conclude representative load balancing designed for data center networks in recent years. Among the two categories, namely centralized and distributed schemes, there are superb proposals concerning different specific aims and scenarios. Hedera is a centralized algorithm which aim at large traffic flows while Fastpass is hybrid structure of centralized and distributed schemes. MPTCP is a modification on TCP which assists the process of collection of congestion information. Served for leaf-spine topology, CONGA is a classic algorithm whose performance is nearly optimal by utilizing the virtualization techniques and flow let design. CLOVE is another algorithm that uses the ECN marks in the network virtualization to collect congestion information, while Expeditus is aimed at solving the problem of Clos architecture. Based on ECMP, Presto achieves the optimal balancing in an asymmetric topology and LocalFlow, as its name shows, is a scheme employs OpenFlow switches to achieve local path selection. DRILL, on the other hand, do not need to change any switch hardware or transfer protocols. It investigates a different direction to improve load balancing using a smarter fabric. We also study flow scheduling algorithm in CPU scheduling and switches in data center networks. There are multiple comon-used queue-based methods: First-Come First-Serve, Round-Robin, Shortest Job First and Multi Level Feedback Queue. Bai Wei et al. employ MLFQ into switches in data center networks and proposed an architecture called PIAS to greatly solve the flow scheduling problem. Later on they proposed AuTO, another dynamic online learning algorithm to further address the problem better.

We demonstrate our traffic optimization system in the last chapter. We first introduce the architecture, a hybrid structure which combines distributed load balancing algorithm and centralized flow scheduling algorithm. The centralized component would use stochastic policy gradient algorithm to deal with large flows after given the calculated threshold for judgment, whereas the short flows are directly processed by the MLFQ and transfer to certain paths selected by the DRILL algorithm. The centralized component utilize the Deep Deterministic Policy Gradient algorithm to determine the proper threshold for the MLFQ after training sufficiently (about 8 hours) on GPUs. The metrics regarding the FCT and link utilization comparing with other baseline algorithms are also shown in the chapter to demonstrate a better performance before we conclude the whole thesis in the end.

\end{bigabstract}
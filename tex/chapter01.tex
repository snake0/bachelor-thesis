%# -*- coding: utf-8-unix -*-
%%==================================================
%% chapter01.tex for SJTU Bachelor Thesis
%%==================================================

%\bibliographystyle{sjtu2}%[此处用于每章都生产参考文献]
\chapter{绪论}
\label{chap:Intro}
\section{研究背景与意义}
随着单机纵向扩展的难度越来越大、价格越来越昂贵，横向扩展架构越来越收到企业用户的青睐。由大量价格低廉的普通机器组成的分布式系统满足了海量数据处理、机器学习等应用的资源需求，降低了企业的硬件成本，同时满足了企业的业务需求。然而，分布式系统对系统软件的开发者提出了新的挑战。如果一个应用程序想要运行在分布式平台之上，则必须调用分布式框架的相关接口，如MapReduce\cite{MapReduce}框架，甚至修改其内部逻辑。这将会带来很大的工作量，使得应用程序无法便利地使用分布式系统，削弱了分布式平台的优势。巨型虚拟机（Giant Virtual Machine）\cite{giantvm}解决了现有程序和分布式系统的兼容问题，它向上层应用提供了一个单一的操作系统镜像，使得现有软件无需修改即可运行在分布式系统之上。虽然巨型虚拟机极大地提高了开发者使用分布式平台的便利性，分布式系统资源使用率偏低的问题依然没有得到解决。阿里巴巴等技术企业提供的数据表明，数据中心的平均CPU使用率维持在30\%左右，不超过40\%\footnote{不进行任务混部，则仅有20\%的CPU利用率，详见https://102.alibaba.com/detail/?id=61}。

一般而言，提高分布式系统资源使用率的方法是将时延敏感型任务（Latency Critical，LC）和尽力而为型任务（Best Effort，BE）进行混部（Colocation）。时延敏感型任务对资源的要求十分苛刻，为了保证其QoS不受到影响（Quality of Service），一般不与其他时延敏感型任务混部，调度器为其提供充足的执行资源，而可以将多个BE型任务与LC型任务进行混部，从而提高集群的资源利用率。然而，由于任务的工作负载在不断变化，为LC型任务提供的资源无法被其充分利用，而资源重分配（Resource Reallocation）可以适应不断变化的工作负载。目前实现资源重分配的方式有进程级迁移（process migration），但进程之间共享了许多数据，例如打开的文件、共享内存等数据结构，使得被迁移的进程在迁移之后依然依赖于源节点，即残余依赖（residual dependencies）\cite{residual}问题；而虚拟机热迁移（VM Live Migration）\cite{livemigration}则涉及对整个操作系统状态的迁移，会产生巨大的网络开销。

巨型虚拟机将分布式系统抽象为简单的单一的客户机操作系统，隐藏了分布式系统的复杂性，可以仅仅通过调度客户机内部进程完成集群中工作负载的迁移。本文通过编写操作系统内部的调度脚本，动态感知工作负载，实现了集群节点间的load balancing（均衡负载），在提高集群总体CPU使用率的同时，满足了集群中LC型任务的服务质量不被影响的要求。为了进一步减小集群间任务调度的网络开销、提高集群CPU资源利用率，本文利用Google trace\footnote{谷歌Borg集群29天内获得的任务调度与资源用量数据：https://github.com/google/cluster-data}对分布式集群进行仿真，模拟各类调度策略，研究了不同调度算法以及参数对集群性能、网络开销的影响。

\section{研究现状}
\label{chap:dissch}
在分布式集群的调度策略方面，Mesos\cite{mesos}设计了细粒度的资源分配器，然而由于现今的分布式框架都带有极其复杂的调度器，彼此之间相互影响，因此Mesos添加了双层调度器，在各个分布式框架之间进行协调，使得各个框架达到最优的数据局部性（data locality）。Omega\cite{omega}是谷歌的分布式集群管理系统，其核心是一个共享状态、无锁的分布式调度器，调度过程的延迟大大下降，相比于集中式的集群调度器更好地应对了集群中任务对资源需求的极速变化。随着数据处理任务的并行度越来越高，以及对延迟要求越来越高，Sparrow\cite{sparrow}提出了一个分布式的、细粒度的调度器，解决了集中式采样系统造成的吞吐量下降、延迟上升的问题。Graphene\cite{graphene}关注的是分布式系统中任务之间的依赖关系，以及多元化的资源需求。在并行数据处理系统中，任务之间的依赖关系网（DAG），是调度器作出调度决策时所关注的主要信息。Graphene在任务运行时计算出任务之间的DAG，对未来的调度决策进行改进。

\section{本文工作}
资源重分配是动态平衡集群工作负载的方案，可通过集群中工作负载的动态迁移提高集群总体的资源使用率。而进程迁移有残余依赖问题，不予考虑，而相较于虚拟机的热迁移，容器热迁移具有较高的下线时间（downtime）。为了避免虚拟机热迁移造成的巨大的网络开销和迁移过程中客户机进程的下线时间，本文用分布式虚拟机客户机内的进程调度器代替虚拟机的热迁移，将分布式虚拟机GiantVM（巨型虚拟机）部署在集群中，编写巨型虚拟机客户机的shell调度脚本，动态感知集群节点负载，在节点之间按需调度客户机进程，达到了集群中资源重分配的目的，提高了集群总体的CPU使用率。而分布式虚拟机中客户机进程的迁移仅涉及较少几部分的内存页传输，网络开销远小于虚拟机热迁移，又消除了下线时间，是高效的迁移方式。本文还使用了谷歌Borg集群提供的$task\_usage$、$task\_event$两组数据。这两组数据在较长时间段内对集群的工作负载进行追踪，可以用来模拟一个高度仿真的由800台相同机器组成的分布式集群。我们在此模拟集群上对巨型虚拟机的迁移过程进行仿真，测试了较长工作时间内调度脚本的负载平衡性能。本文还分析了调度脚本的可优化空间，设计了更细粒度的调度算法，从而使得平衡效果更强；同时将被迁移的进程按照CPU、内存两类指标进行排序，进一步优化了调度算法的平衡能力，减小了平衡过程的网络开销。


\section{本文结构}
本文将按如下步骤进行叙述：
\begin{itemize}
  \item 第一章介绍了本文所做工作的背景和研究意义，大致描述了本文的工作背景、工作成果以及本文的行文结构。
  \item 第二章介绍了本文的技术背景，包含进程的内存布局、NUMA架构相关优化，以及巨型虚拟机的实现架构对客户机内任务的性能影响，最后分析比较了数据中心任务负载的三种迁移方式，引出后文巨型虚拟机内调度器的设计。
  \item 第三章介绍了本文调度器的设计理念和设计目标，并介绍了shell语言实现的粗粒度巨型虚拟机任务调度器，分析了其性能优势。
  \item 第四章描述了集群追踪数据各个字段的含义，讲述了如何利用追踪数据搭建仿真环境，模拟了粗粒度调度器，还设计了细粒度的调度算法，并提出了不同的进程排序方式。
  \item 第五章首先对真实环境下的巨型虚拟机平衡算法进行测试，验证shell脚本的平衡功效，再对仿真环境下的粗粒度调度器和细粒度调度器分别进行测试，对比分析了不同的进程排序方式对细粒度调度器性能的影响。
  \item 第六章对本文的设计成果做了总结，并分析了当前设计的优点和不足，提出了未来工作的方向。
\end{itemize}
